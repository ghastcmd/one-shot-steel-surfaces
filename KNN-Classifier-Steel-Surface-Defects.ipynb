{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## KNN Classifier for Steel surface defect recognition\n",
    "\n",
    "#### If you use this code, please cite our work: [[paper](https://doi.org/10.1016/j.promfg.2020.05.146)][[code](https://github.com/adipandas/one-shot-steel-surfaces)]\n",
    "\n",
    "### Aditya M. Deshpande, Ali A. Minai, Manish Kumar, One-Shot Recognition of Manufacturing Defects in Steel Surfaces, Procedia Manufacturing, Volume 48, 2020, Pages 1064-1071, ISSN 2351-9789, https://doi.org/10.1016/j.promfg.2020.05.146.\n",
    "\n",
    "#### MIT License\n",
    "\n",
    "Copyright (c) 2020 Aditya M. Deshpande\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "### Note: for this case, the number of neighbors in KNN were set to `1` and the dataset was also configured accordingly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from imutils import paths\r\n",
    "import numpy as np\r\n",
    "import argparse\r\n",
    "import imutils\r\n",
    "import cv2\r\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### KNN classifier arguments\n",
    "\n",
    "#### NOTE: You may need to change the path in the below dictionary as per your dataset "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "args = {'training_dataset': './datasets_all/knn_data/training',\r\n",
    "        'testing_dataset': './datasets_all/knn_data/testing',\r\n",
    "        'neighbors': 1,\r\n",
    "        'jobs': 1}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convert image to Vector\n",
    "Function to *resize* the image to a fixed size, then flatten the image into a list of raw pixel intensities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def image_to_feature_vector(image, size=(32, 32)):\r\n",
    "    return cv2.resize(image, size).flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract a 3D color histogram from the HSV color space using the supplied number of `bins` per channel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "def extract_color_histogram(image, bins=(8, 8, 8)):\r\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\r\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\r\n",
    "    cv2.normalize(hist, hist)\r\n",
    "    return hist.flatten()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Image paths"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "imagePaths = list(paths.list_images(args[\"training_dataset\"]))\r\n",
    "imagePaths_test = list(paths.list_images(args[\"testing_dataset\"]))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper function to prepare data\n",
    "* Extract each image and corresponding class label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def prepare_data(imagePaths):\r\n",
    "    rawImages, features, labels = [], [], []\r\n",
    "    \r\n",
    "    for (i, imagePath) in enumerate(imagePaths):    \r\n",
    "        image = cv2.imread(imagePath)\r\n",
    "        label = imagePath.split(os.path.sep)[-1].split(\".\")[0].split(\"_\")[0]\r\n",
    "        pixels = image_to_feature_vector(image)\r\n",
    "        hist = extract_color_histogram(image)\r\n",
    "        \r\n",
    "        rawImages.append(pixels)\r\n",
    "        features.append(hist)\r\n",
    "        labels.append(label)\r\n",
    "    \r\n",
    "    return rawImages, features, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load training and testing data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "train_images, train_features, train_labels = prepare_data(imagePaths)\r\n",
    "test_images, test_features, test_labels = prepare_data(imagePaths_test)\r\n",
    "\r\n",
    "print(\"[INFO] Shape of the image sampled from dataset:\", train_images[0].shape)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LOCALH~1\\AppData\\Local\\Temp/ipykernel_13364/2375223754.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagePaths_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[INFO] Shape of the image sampled from dataset:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Memory consumed by the raw images matrix and features matrix\r\n",
    "\r\n",
    "##### Training set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trainRI = np.array(train_images)\r\n",
    "trainRL = np.array(train_labels)\r\n",
    "trainF = np.array(train_features)\r\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(trainRI.nbytes / (1024 * 1000.0)))\r\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(trainF.nbytes / (1024 * 1000.0)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] pixels matrix: 0.02MB\n",
      "[INFO] features matrix: 0.01MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Testing set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testRI = np.array(test_images)\r\n",
    "testRL = np.array(test_labels)\r\n",
    "testF = np.array(test_features)\r\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(testRI.nbytes / (1024 * 1000.0)))\r\n",
    "print(\"[INFO] features matrix: {:.2f}MB\".format(testF.nbytes / (1024 * 1000.0)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] pixels matrix: 5.40MB\n",
      "[INFO] features matrix: 3.60MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate the k-NN classifer on the raw pixel intensities"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"[INFO] evaluating raw pixel accuracy...\")\r\n",
    "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"], n_jobs=args[\"jobs\"])\r\n",
    "model.fit(trainRI, trainRL)\r\n",
    "acc = model.score(testRI, testRL)\r\n",
    "\r\n",
    "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc * 100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] evaluating raw pixel accuracy...\n",
      "[INFO] raw pixel accuracy: 28.22%\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "e2b6c2d7d9ddd64edc1a9f96033484bf1fa809b0d53b1acdc555142cab2cb3aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}